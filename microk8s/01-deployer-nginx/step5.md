# Ã‰tape 5 : Scaler l'Application

## ğŸ“ Objectif

Apprendre Ã  **scaler horizontalement** votre application pour gÃ©rer plus de charge.

## ğŸ“ Qu'est-ce que le Scaling Horizontal ?

Le **scaling horizontal** consiste Ã  augmenter le nombre de pods (rÃ©plicas) :
- âœ… Plus de pods = plus de capacitÃ© Ã  traiter des requÃªtes
- âœ… Haute disponibilitÃ© : si un pod crash, les autres continuent
- âœ… Kubernetes distribue automatiquement la charge

## ğŸ“ˆ Scaler de 2 Ã  5 RÃ©plicas

Une seule commande pour passer de 2 Ã  5 pods :

```bash
microk8s kubectl scale deployment nginx-deployment --replicas=5
```{{exec}}

## ğŸ‘€ Observer les Pods se CrÃ©er

```bash
microk8s kubectl get pods -l app=nginx
```{{exec}}

Vous devriez maintenant voir **5 pods** !

## â±ï¸ Voir la CrÃ©ation en Temps RÃ©el

LanÃ§ons le scaling encore plus haut et observons en temps rÃ©el :

```bash
# Scaler Ã  8 rÃ©plicas
microk8s kubectl scale deployment nginx-deployment --replicas=8

# Observer en temps rÃ©el (rafraÃ®chissement toutes les 2 secondes)
watch -n 2 'microk8s kubectl get pods -l app=nginx'
```{{exec}}

Vous verrez les nouveaux pods passer de **Pending** â†’ **ContainerCreating** â†’ **Running**.

Appuyez sur **Ctrl+C** pour arrÃªter le watch.

## ğŸ”— VÃ©rifier les Endpoints du Service

Le Service a automatiquement dÃ©tectÃ© les nouveaux pods :

```bash
microk8s kubectl get endpoints nginx-service
```{{exec}}

Vous devriez maintenant voir **8 IPs** dans les endpoints !

## ğŸ“Š Voir l'Historique du Scaling

```bash
microk8s kubectl describe deployment nginx-deployment | grep -A 5 "Events:"
```{{exec}}

Vous verrez l'historique des opÃ©rations de scaling dans les Events.

## ğŸ“‰ Scaler vers le Bas

On peut aussi rÃ©duire le nombre de replicas pour Ã©conomiser des ressources :

```bash
microk8s kubectl scale deployment nginx-deployment --replicas=3
```{{exec}}

VÃ©rifiez que Kubernetes supprime automatiquement les pods en trop :

```bash
microk8s kubectl get pods -l app=nginx
```{{exec}}

Vous devriez voir certains pods en Ã©tat **Terminating**, puis seulement **3 pods Running**.

## ğŸ” VÃ©rification Finale

```bash
# Combien de pods Running ?
microk8s kubectl get pods -l app=nginx --no-headers | grep Running | wc -l

# Combien de replicas configurÃ©s ?
microk8s kubectl get deployment nginx-deployment -o jsonpath='{.spec.replicas}'
echo ""

# Combien de replicas disponibles ?
microk8s kubectl get deployment nginx-deployment -o jsonpath='{.status.availableReplicas}'
echo ""
```{{exec}}

Tous les chiffres devraient Ãªtre **3** !

## ğŸ“ Modifier le YAML Directement

Vous pouvez aussi modifier le nombre de replicas en Ã©ditant le fichier YAML :

```bash
# Ouvrir l'Ã©diteur
nano nginx-deployment.yaml
```

Changez `replicas: 2` en `replicas: 4`, puis sauvegardez (**Ctrl+O**, **Enter**, **Ctrl+X**).

Appliquez la modification :

```bash
microk8s kubectl apply -f nginx-deployment.yaml
```{{exec}}

## ğŸ¯ Points ClÃ©s

- âœ… Le scaling est **instantanÃ©** avec une simple commande
- âœ… Kubernetes crÃ©e/supprime automatiquement les pods
- âœ… Le Service dÃ©tecte automatiquement les nouveaux pods
- âœ… Pas de downtime : les pods existants continuent de tourner
- âœ… En production, on peut utiliser l'**Horizontal Pod Autoscaler (HPA)** pour du scaling automatique basÃ© sur le CPU/RAM

## ğŸ’¡ Autoscaling Automatique (Bonus)

En production, on configure un HPA pour que Kubernetes scale automatiquement :

```bash
# Exemple (ne pas exÃ©cuter maintenant)
kubectl autoscale deployment nginx-deployment \
  --min=2 --max=10 --cpu-percent=70
```

Cela signifie : "Maintiens entre 2 et 10 pods, et ajoute des pods si le CPU dÃ©passe 70%"

---

Cliquez sur **Continue** pour explorer les logs.
